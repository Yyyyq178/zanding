import torch
import torch.nn.functional as F
from models import mar
from models.vae import AutoencoderKL

def test_dynamic_resolution():
    print("ğŸš€ å¼€å§‹æµ‹è¯•è¿ç»­å°ºåº¦/å¤šåˆ†è¾¨ç‡åŠŸèƒ½...")
    device = "cuda" if torch.cuda.is_available() else "cpu"

    # ================= 1. åˆå§‹åŒ–æ¨¡å‹ =================
    # ä½¿ç”¨ä½ å½“å‰çš„é…ç½® (128x128 è®­ç»ƒé…ç½®)
    print("1. åŠ è½½æ¨¡å‹é…ç½®...")
    # æ³¨æ„: è¿™é‡Œçš„ img_size å’Œ buffer_size åªæ˜¯åˆå§‹åŒ–å‚æ•°ï¼Œ
    # å¦‚æœæˆ‘ä»¬çš„åŠ¨æ€é€»è¾‘å†™å¯¹äº†ï¼Œæ¨ç†æ—¶ä¼ å…¥ä¸åŒå°ºå¯¸åº”è¯¥ä¹Ÿèƒ½è·‘ã€‚
    model = mar.mar_base(
        img_size=128,         # è®­ç»ƒæ—¶çš„è®¾ç½®
        buffer_size=4,        # è®­ç»ƒæ—¶çš„è®¾ç½® (LR 32x32 -> 2x2=4 tokens)
        vae_stride=16,
        patch_size=1,
        diffloss_d=6,
        diffloss_w=1024
    ).to(device).eval()

    # åŠ è½½æƒé‡ (å¦‚æœæœ‰çš„è¯ï¼Œæ²¡æœ‰ä¹Ÿè¡Œï¼Œæˆ‘ä»¬ä¸»è¦æµ‹ä»£ç é€»è¾‘æ˜¯å¦å´©)
    # try:
    #     ckpt = torch.load("output_sr_train/checkpoint-last.pth", map_location='cpu')
    #     model.load_state_dict(ckpt['model'], strict=False)
    #     print("   æˆåŠŸåŠ è½½è®­ç»ƒæƒé‡ï¼")
    # except:
    #     print("   âš ï¸ æœªæ‰¾åˆ°æƒé‡ï¼Œä½¿ç”¨éšæœºæƒé‡æµ‹è¯•é€»è¾‘...")

    # ================= 2. æµ‹è¯•æ¡ˆä¾‹ =================
    
    # æ¡ˆä¾‹ A: æ ‡å‡†æ­£æ–¹å½¢ (è®­ç»ƒå°ºå¯¸)
    # LR: 32x32 -> HR: 128x128
    run_case(model, device, lr_h=32, lr_w=32, scale=4, name="æ ‡å‡† 128x128")

    # æ¡ˆä¾‹ B: é•¿æ–¹å½¢ (å®½å›¾)
    # LR: 32x64 -> HR: 128x256
    # è¿™æ˜¯æµ‹è¯• "2D Grid" æ˜¯å¦è§£è€¦äº† H å’Œ W
    #run_case(model, device, lr_h=32, lr_w=64, scale=4, name="é•¿æ–¹å½¢ 128x256")

    # æ¡ˆä¾‹ C: éæ•´æ•°å€ç‡ / ä»»æ„ç›®æ ‡å°ºå¯¸ (è¿ç»­å°ºåº¦)
    # LR: 32x32 -> HR: 64x64 (2å€è¶…åˆ†)
    # è®­ç»ƒæ—¶æˆ‘ä»¬åªæ•™äº†å®ƒ 4 å€ï¼Œç°åœ¨å¼ºè¡Œè®©å®ƒåš 2 å€
    # å¦‚æœä½ç½®ç¼–ç æ’å€¼é€»è¾‘æ˜¯å¯¹çš„ï¼Œè¿™åº”è¯¥èƒ½è·‘é€š
    run_case(model, device, lr_h=32, lr_w=32, scale=2, name="2å€è¶…åˆ† (éæ ‡å€ç‡)")

    print("\nğŸ‰ å…¨éƒ¨æµ‹è¯•é€šè¿‡ï¼ä½ çš„æ¨¡å‹ç°åœ¨æ”¯æŒä»»æ„åˆ†è¾¨ç‡å’Œæ¯”ä¾‹ï¼")

def run_case(model, device, lr_h, lr_w, scale, name):
    print(f"\nğŸ§ª æµ‹è¯•æ¡ˆä¾‹: {name}")
    print(f"   è¾“å…¥ LR å°ºå¯¸: {lr_h} x {lr_w}")
    
    # 1. æ„é€ å‡ LR Latent
    # VAE Stride = 16
    feat_h = lr_h // 16
    feat_w = lr_w // 16
    if feat_h == 0 or feat_w == 0: feat_h, feat_w = 1, 1 # æœ€å°ä¿æŠ¤
    
    # æ¨¡æ‹Ÿ VAE è¾“å‡ºçš„ Latent [B, 16, h, w]
    x_lr = torch.randn(1, 16, feat_h, feat_w).to(device)
    print(f"   LR Latent grid: {feat_h} x {feat_w}")

    # 2. è®¡ç®—ç›®æ ‡ HR å°ºå¯¸
    target_h = feat_h * scale
    target_w = feat_w * scale
    print(f"   ç›®æ ‡ HR Latent grid: {target_h} x {target_w}")

    # 3. è¿è¡Œæ¨ç†
    try:
        with torch.no_grad():
            # ä¼ å…¥ target_shape=(h, w)
            # æ³¨æ„ï¼šsample_tokens å†…éƒ¨åº”è¯¥ä¼šè‡ªåŠ¨å¤„ç† mask å’Œ tokens çš„åˆå§‹åŒ–å¤§å°
            out_tokens = model.sample_tokens(
                bsz=1, 
                num_iter=2, # è·‘ä¸¤æ­¥æ„æ€ä¸€ä¸‹
                x_lr=x_lr, 
                target_seq_len=target_h*target_w, # ğŸŸ¢ å…³é”®å‚æ•°
                progress=False
            )
            
        # 4. æ£€æŸ¥è¾“å‡º
        # out_tokens åº”è¯¥æ˜¯ [1, 16, target_h, target_w] (unpatchify å)
        print(f"   æ¨¡å‹è¾“å‡ºå½¢çŠ¶: {out_tokens.shape}")
        
        if out_tokens.shape[-2:] == (target_h, target_w):
            print("   âœ… å½¢çŠ¶åŒ¹é…æˆåŠŸï¼")
        else:
            print(f"   âŒ å½¢çŠ¶ä¸åŒ¹é…ï¼é¢„æœŸ {(target_h, target_w)}ï¼Œå®é™… {out_tokens.shape[-2:]}")
            
    except Exception as e:
        print(f"   âŒ æŠ¥é”™å´©æºƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_dynamic_resolution()